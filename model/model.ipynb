{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTAjn9eBhhJ8"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mTraceback (most recent call last):\n",
            "\u001b[1;31m  File \"/home/lance/.vscode/extensions/ms-toolsai.jupyter-2022.9.1303220346/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
            "\u001b[1;31m    from notebook import notebookapp as app\n",
            "\u001b[1;31m  File \"/home/lance/.local/lib/python3.8/site-packages/notebook/notebookapp.py\", line 80, in <module>\n",
            "\u001b[1;31m    from .services.contents.manager import ContentsManager\n",
            "\u001b[1;31m  File \"/home/lance/.local/lib/python3.8/site-packages/notebook/services/contents/manager.py\", line 17, in <module>\n",
            "\u001b[1;31m    from nbformat import sign, validate as validate_nb, ValidationError\n",
            "\u001b[1;31m  File \"/home/lance/.local/lib/python3.8/site-packages/nbformat/sign.py\", line 26, in <module>\n",
            "\u001b[1;31m    from traitlets import (\n",
            "\u001b[1;31mImportError: cannot import name 'Callable' from 'traitlets' (/usr/lib/python3/dist-packages/traitlets/__init__.py)\n",
            "\u001b[1;31m\n",
            "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31m\n",
            "\u001b[1;31mTraceback (most recent call last):\n",
            "\u001b[1;31m  File \"/home/lance/.vscode/extensions/ms-toolsai.jupyter-2022.9.1303220346/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
            "\u001b[1;31m    return func(self, *args, **kwargs)\n",
            "\u001b[1;31m  File \"/home/lance/.vscode/extensions/ms-toolsai.jupyter-2022.9.1303220346/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
            "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
            "\u001b[1;31m  File \"/home/lance/.vscode/extensions/ms-toolsai.jupyter-2022.9.1303220346/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
            "\u001b[1;31m    from notebook import app as app\n",
            "\u001b[1;31mImportError: cannot import name 'app' from 'notebook' (/home/lance/.local/lib/python3.8/site-packages/notebook/__init__.py)\n",
            "\u001b[1;31m\n",
            "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/home/lance/eecs583/EECS583_Unroll_ML/model\" --config=/tmp/384e2155-0539-4b64-9940-390dfd7cf216/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader    # dataset representation and loading\n",
        "import torch.nn as nn                     # neural networks\n",
        "import torch.nn.functional as F           # layers, activations and more\n",
        "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
        "import numpy as np\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with 'Python 3.8.10 64-bit' requires jupyter and notebook package.\n",
            "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
            "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
            "\u001b[1;31mor\n",
            "\u001b[1;31mconda install jupyter notebook -U'\n",
            "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "device = None\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU\")\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"NOTE: Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CSVDataset(Dataset): \n",
        "    # 9 feats: trip count, num ops, num operands, num mem ops, num fops, num branches, est resmii, frequent path length, depth of loop\n",
        "\n",
        "    def __init__(self, csv_path):\n",
        "        csv_reader = csv.reader(open(csv_path, 'r'), delimiter=',')\n",
        "\n",
        "        self.csv_lines = []\n",
        "        for line in csv_reader:\n",
        "            self.csv_lines.append(line)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.csv_lines)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # line = [prob_name, f1, ... , f9, label, rank1, ..., rank8, time1, ..., time8]\n",
        "        line = self.csv_lines[idx]\n",
        "        X = torch.FloatTensor(line[1:10])\n",
        "        y = line[10]\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUoVVslNghrg"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,input_size,hidden_dim_1,hidden_dim_2,num_classes,drop_prob=0.5):\n",
        "        super(MLP, self).__init__()\n",
        "        #Put GeneModel architecture here (WITHOUT THE FINAL LAYERS)\n",
        "        self.hidden_dim_1=hidden_dim_1\n",
        "        self.hidden_dim_2=hidden_dim_2\n",
        "        self.num_classes=num_classes\n",
        "        \n",
        "        #self.flantten=torch.flatten()\n",
        "        self.fc_1=nn.Linear(input_size,hidden_dim_1)\n",
        "        self.fc_2=nn.Linear(hidden_dim_1,hidden_dim_2)\n",
        "        self.fc_3=nn.Linear(hidden_dim_2,num_classes)\n",
        "\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #Put GeneModel architecture here (WITHOUT THE FINAL LAYERS)\n",
        "        x=x.float()\n",
        "        #x=torch.flatten(x).float()\n",
        "        x=self.fc_1(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.fc_2(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.fc_3(x)\n",
        "        return x\n",
        "    \n",
        "    # def train(self, trainloader, optimizer, n_epochs = 30):\n",
        "    #     train_loss = 0\n",
        "    #     losses_epochs = []\n",
        "    #     for epoch in range(n_epochs):\n",
        "    #         print(\"Starting epoch: \", epoch)\n",
        "    #         for X, y in train_batch:\n",
        "    #             optimizer.zero_grad()\n",
        "\n",
        "    #             outputs = self(X1, X2)\n",
        "    #             loss = self.criterion(outputs, y)\n",
        "    #             loss.backward()\n",
        "    #             optimizer.step()\n",
        "    #             train_loss += loss.item()\n",
        "    #         print(\"train loss:\", train_loss)\n",
        "    #         losses_epochs.append(train_loss)\n",
        "    #         train_loss = 0\n",
        "    #     return losses_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5UM0JlKhMz7"
      },
      "outputs": [],
      "source": [
        "mlp = MLP(8,8,8,8)\n",
        "train_csv = \"mock_train.csv\"\n",
        "val_csv = \"mock_val.csv\"\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = optim.Adam(mlp.parameters(), lr=lr)\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# Dataloader\n",
        "train_dataset = CSVDataset(train_csv)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = CSVDataset(val_csv)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in epochs:\n",
        "    for X, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = mlp(X)\n",
        "        loss = mlp.loss_function(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    mlp.eval()\n",
        "    for X, y in val_loader:\n",
        "        pred = mlp(X)\n",
        "        val_loss = mlp.loss_function(pred, y)\n",
        "    \n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
