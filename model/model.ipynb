{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lxguan1/EECS583_Unroll_ML.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJok6WMWqj2_",
        "outputId": "45656ec2-8fa7-4822-da9c-c74bd27d278b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EECS583_Unroll_ML' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/EECS583_Unroll_ML/\n",
        "!git fetch\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22pMfqertaqH",
        "outputId": "3ca6464f-0a07-4a29-e518-18bd95fc6730"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EECS583_Unroll_ML\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 14 (delta 6), reused 14 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (14/14), done.\n",
            "From https://github.com/lxguan1/EECS583_Unroll_ML\n",
            "   36ee999..2cf32ca  main       -> origin/main\n",
            "Updating 36ee999..2cf32ca\n",
            "Fast-forward\n",
            " data/{unroll_ranks.csv => combined_labels.csv}     |  484 \u001b[32m+\u001b[m\u001b[31m--\u001b[m\n",
            " data/feat_labels_combined.csv                      | 3658 \u001b[32m++++++++++++++++++++\u001b[m\n",
            " data/train.csv                                     | 2932 \u001b[32m++++++++++++++++\u001b[m\n",
            " .../unroll_labels_5678.csv                         |    0\n",
            " data/val.csv                                       |  726 \u001b[32m++++\u001b[m\n",
            " model/model.ipynb                                  |   75 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " util_scripts/combine_feats_and_labels.py           |   19 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " util_scripts/merge_unrolls.py                      |    9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " util_scripts/train_val_split.py                    |   31 \u001b[32m+\u001b[m\n",
            " util_scripts/visualize_label_dist.py               |   35 \u001b[32m+\u001b[m\n",
            " 10 files changed, 7710 insertions(+), 259 deletions(-)\n",
            " rename data/{unroll_ranks.csv => combined_labels.csv} (90%)\n",
            " create mode 100644 data/feat_labels_combined.csv\n",
            " create mode 100644 data/train.csv\n",
            " rename unroll_labels_5678.csv => data/unroll_labels_5678.csv (100%)\n",
            " create mode 100644 data/val.csv\n",
            " create mode 100644 util_scripts/train_val_split.py\n",
            " create mode 100644 util_scripts/visualize_label_dist.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sTAjn9eBhhJ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader    # dataset representation and loading\n",
        "import torch.nn as nn                     # neural networks\n",
        "import torch.nn.functional as F           # layers, activations and more\n",
        "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
        "import numpy as np\n",
        "import csv\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1MJk9DGqV74",
        "outputId": "789a8526-4c5e-4a70-ce7e-b83822013937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the GPU\n"
          ]
        }
      ],
      "source": [
        "device = None\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU\")\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"NOTE: Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6xObrJFJqV77"
      },
      "outputs": [],
      "source": [
        "class CSVDataset(Dataset): \n",
        "    # 9 feats: trip count, num ops, num operands, num mem ops, num fops, num branches, est resmii, frequent path length, depth of loop\n",
        "\n",
        "    def __init__(self, csv_path):\n",
        "        csv_reader = csv.reader(open(csv_path, 'r'), delimiter=',')\n",
        "\n",
        "        # line = [prob_name, f1, ... , f9, rank1, ..., rank8]\n",
        "        self.csv_lines = []\n",
        "        for line in csv_reader:\n",
        "            line = [int(float(item)) for item in line[1:11]]\n",
        "            self.csv_lines.append(line)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.csv_lines)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        line = self.csv_lines[idx]\n",
        "        X = torch.FloatTensor(line[:-1])\n",
        "        y = torch.zeros(8)\n",
        "        y[line[-1] - 1] = 1\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zUoVVslNghrg"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,input_size,hidden_dim_1,hidden_dim_2,num_classes,drop_prob=0.5):\n",
        "        super(MLP, self).__init__()\n",
        "        #Put GeneModel architecture here (WITHOUT THE FINAL LAYERS)\n",
        "        self.hidden_dim_1=hidden_dim_1\n",
        "        self.hidden_dim_2=hidden_dim_2\n",
        "        self.num_classes=num_classes\n",
        "        \n",
        "        #self.flantten=torch.flatten()\n",
        "        self.fc_1=nn.Linear(input_size,hidden_dim_1)\n",
        "        self.fc_2=nn.Linear(hidden_dim_1,hidden_dim_2)\n",
        "        self.fc_3=nn.Linear(hidden_dim_2,num_classes)\n",
        "\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Put GeneModel architecture here (WITHOUT THE FINAL LAYERS)\n",
        "        x=x.float()\n",
        "        #x=torch.flatten(x).float()\n",
        "        x=self.fc_1(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.fc_2(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.fc_3(x)\n",
        "        return x\n",
        "    \n",
        "    # def train(self, trainloader, optimizer, n_epochs = 30):\n",
        "    #     train_loss = 0\n",
        "    #     losses_epochs = []\n",
        "    #     for epoch in range(n_epochs):\n",
        "    #         print(\"Starting epoch: \", epoch)\n",
        "    #         for X, y in train_batch:\n",
        "    #             optimizer.zero_grad()\n",
        "\n",
        "    #             outputs = self(X1, X2)\n",
        "    #             loss = self.criterion(outputs, y)\n",
        "    #             loss.backward()\n",
        "    #             optimizer.step()\n",
        "    #             train_loss += loss.item()\n",
        "    #         print(\"train loss:\", train_loss)\n",
        "    #         losses_epochs.append(train_loss)\n",
        "    #         train_loss = 0\n",
        "    #     return losses_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "g5UM0JlKhMz7"
      },
      "outputs": [],
      "source": [
        "mlp = MLP(input_size=9, hidden_dim_1=8, hidden_dim_2=8, num_classes=8)\n",
        "train_csv = \"/content/EECS583_Unroll_ML/data/train.csv\"\n",
        "val_csv = \"/content/EECS583_Unroll_ML/data/val.csv\"\n",
        "\n",
        "lr = 0.001\n",
        "optimizer = optim.Adam(mlp.parameters(), lr=lr)\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "class_weights = torch.Tensor([2.4433, 6.319, 8.3295, 7.33, 0.371,0.49, 0.7541, 0.8983])\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Dataloader\n",
        "train_dataset = CSVDataset(train_csv)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = CSVDataset(val_csv)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pprh4SjhqV8B",
        "outputId": "24af23af-9ee4-4190-8fce-d24bcd8899f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.8/bdb.py\", line 334, in set_trace\n",
            "    sys.settrace(self.trace_dispatch)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 0 / 29\n",
            "> <ipython-input-45-eff780ddd512>(7)<module>()\n",
            "-> for X, y in train_loader:\n",
            "(Pdb) n\n",
            "> <ipython-input-45-eff780ddd512>(8)<module>()\n",
            "-> optimizer.zero_grad()\n",
            "(Pdb) X\n",
            "tensor([[5.0000e+00, 1.1000e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 1.0100e+02],\n",
            "        [5.0000e+00, 1.1000e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 1.0200e+02],\n",
            "        [5.7000e+01, 9.6000e+01, 3.4000e+01, 0.0000e+00, 7.0000e+00, 3.4000e+01,\n",
            "         2.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [2.6000e+01, 4.3000e+01, 1.5000e+01, 0.0000e+00, 3.0000e+00, 1.5000e+01,\n",
            "         3.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [5.2000e+01, 8.8000e+01, 2.4000e+01, 0.0000e+00, 7.0000e+00, 2.4000e+01,\n",
            "         4.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [2.3000e+01, 4.4000e+01, 1.2000e+01, 0.0000e+00, 3.0000e+00, 1.2000e+01,\n",
            "         3.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [5.0000e+01, 8.3000e+01, 2.7000e+01, 0.0000e+00, 1.0000e+01, 2.7000e+01,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [5.7000e+01, 1.0100e+02, 2.7000e+01, 2.0000e+00, 9.0000e+00, 2.7000e+01,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [5.4000e+01, 8.8000e+01, 2.5000e+01, 0.0000e+00, 7.0000e+00, 2.5000e+01,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [4.3000e+01, 8.1000e+01, 2.3000e+01, 2.0000e+00, 2.0000e+00, 2.3000e+01,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [2.0000e+01, 3.8000e+01, 7.0000e+00, 0.0000e+00, 5.0000e+00, 7.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [2.2000e+01, 3.6000e+01, 1.1000e+01, 0.0000e+00, 5.0000e+00, 1.1000e+01,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [5.0000e+00, 1.1000e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 2.0001e+05],\n",
            "        [1.9000e+01, 3.5000e+01, 6.0000e+00, 0.0000e+00, 5.0000e+00, 6.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [2.6000e+01, 4.3000e+01, 1.6000e+01, 0.0000e+00, 4.0000e+00, 1.6000e+01,\n",
            "         4.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [1.4000e+01, 2.3000e+01, 6.0000e+00, 0.0000e+00, 3.0000e+00, 6.0000e+00,\n",
            "         3.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [2.6000e+01, 4.5000e+01, 1.1000e+01, 0.0000e+00, 5.0000e+00, 1.1000e+01,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [2.2000e+01, 5.2000e+01, 6.0000e+00, 0.0000e+00, 3.0000e+00, 6.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [1.3000e+01, 2.1000e+01, 6.0000e+00, 0.0000e+00, 3.0000e+00, 6.0000e+00,\n",
            "         3.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [1.6000e+01, 3.4000e+01, 5.0000e+00, 0.0000e+00, 3.0000e+00, 5.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [2.3000e+01, 4.1000e+01, 1.6000e+01, 0.0000e+00, 3.0000e+00, 1.6000e+01,\n",
            "         3.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [2.4000e+01, 4.0000e+01, 1.4000e+01, 0.0000e+00, 3.0000e+00, 1.4000e+01,\n",
            "         3.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [5.1000e+01, 1.0600e+02, 1.8000e+01, 0.0000e+00, 7.0000e+00, 1.8000e+01,\n",
            "         1.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [1.3000e+01, 2.2000e+01, 6.0000e+00, 0.0000e+00, 2.0000e+00, 6.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [1.7000e+01, 2.6000e+01, 1.0000e+01, 0.0000e+00, 3.0000e+00, 1.0000e+01,\n",
            "         3.0000e+00, 3.0000e+00, 0.0000e+00],\n",
            "        [3.1000e+01, 5.2000e+01, 1.2000e+01, 0.0000e+00, 6.0000e+00, 1.2000e+01,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [5.6000e+01, 9.8000e+01, 2.1000e+01, 0.0000e+00, 1.0000e+01, 2.1000e+01,\n",
            "         2.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [5.0000e+00, 1.1000e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
            "         2.0000e+00, 1.0000e+00, 5.0000e+06],\n",
            "        [6.9000e+01, 1.1800e+02, 3.8000e+01, 0.0000e+00, 6.0000e+00, 3.8000e+01,\n",
            "         2.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "        [2.6000e+01, 4.1000e+01, 1.2000e+01, 0.0000e+00, 4.0000e+00, 1.2000e+01,\n",
            "         4.0000e+00, 3.0000e+00, 0.0000e+00],\n",
            "        [2.4000e+01, 4.3000e+01, 1.3000e+01, 0.0000e+00, 2.0000e+00, 1.3000e+01,\n",
            "         2.0000e+00, 1.0000e+00, 0.0000e+00],\n",
            "        [2.7000e+01, 4.1000e+01, 1.6000e+01, 0.0000e+00, 3.0000e+00, 1.6000e+01,\n",
            "         3.0000e+00, 1.0000e+00, 0.0000e+00]])\n",
            "(Pdb) X[0]\n",
            "tensor([  5.,  11.,   1.,   0.,   1.,   1.,   2.,   1., 101.])\n",
            "(Pdb) y[0]\n",
            "tensor([0., 0., 0., 0., 1., 0., 0., 0.])\n",
            "(Pdb) n\n",
            "> <ipython-input-45-eff780ddd512>(9)<module>()\n",
            "-> pred = mlp(X)\n",
            "(Pdb) n\n",
            "> <ipython-input-45-eff780ddd512>(10)<module>()\n",
            "-> loss = criterion(pred, y)\n",
            "(Pdb) pred.shape\n",
            "torch.Size([32, 8])\n",
            "(Pdb) pred[0]\n",
            "tensor([ 4.5145, -3.3563,  1.8899,  1.5965, -5.3171, -3.9895, -1.9650, -7.7047],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "(Pdb) F.cross_entropy(pred, y)\n",
            "tensor(14366.5352, grad_fn=<DivBackward1>)\n",
            "(Pdb) F.cross_entropy(pred[0], y[0])\n",
            "tensor(9.9526, grad_fn=<DivBackward1>)\n",
            "--KeyboardInterrupt--\n",
            "--KeyboardInterrupt--\n",
            "(Pdb) q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.8/bdb.py\", line 359, in set_quit\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BdbQuit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-eff780ddd512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-eff780ddd512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i, epoch in enumerate(range(epochs)):\n",
        "    print(f\"EPOCH {i} / {epochs - 1}\")\n",
        "    \n",
        "    mlp.train()\n",
        "    train_loss = 0.0\n",
        "    pdb.set_trace()\n",
        "    for X, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = mlp(X)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    print(\"Training loss =\", train_loss / len(train_loader))\n",
        "\n",
        "    with torch.no_grad():\n",
        "      mlp.eval()\n",
        "      val_loss_sum = 0.0\n",
        "      for X, y in val_loader:\n",
        "          pred = mlp(X)\n",
        "          val_loss = mlp.loss_function(pred, y)\n",
        "          val_loss_sum += val_loss.item()\n",
        "    print(\"Validation loss =\", val_loss_sum / len(val_loader))\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}