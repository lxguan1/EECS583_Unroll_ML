{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lxguan1/EECS583_Unroll_ML/blob/main/model/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sTAjn9eBhhJ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader    # dataset representation and loading\n",
        "import torch.nn as nn                     # neural networks\n",
        "import torch.nn.functional as F           # layers, activations and more\n",
        "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
        "import numpy as np\n",
        "import csv\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1MJk9DGqV74",
        "outputId": "f1e1e08b-374e-4008-a972-ff0796c36c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the GPU\n"
          ]
        }
      ],
      "source": [
        "device = None\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using the GPU\")\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"NOTE: Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6xObrJFJqV77"
      },
      "outputs": [],
      "source": [
        "class CSVDataset(Dataset): \n",
        "    # 9 feats: trip count, num ops, num operands, num mem ops, num fops, num branches, est resmii, frequent path length, depth of loop\n",
        "\n",
        "    def __init__(self, csv_path):\n",
        "        csv_reader = csv.reader(open(csv_path, 'r'), delimiter=',')\n",
        "\n",
        "        # line = [prob_name, f1, ... , f9, rank1, ..., rank8]\n",
        "        self.csv_lines = []\n",
        "        for line in csv_reader:\n",
        "            row = [float(item) for item in line[1:10]]\n",
        "            row.append(int(line[11]))\n",
        "            self.csv_lines.append(row)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.csv_lines)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        line = self.csv_lines[idx]\n",
        "        X = torch.FloatTensor(line[:-1])\n",
        "        y = torch.zeros(8)\n",
        "        y[line[-1] - 1] = 1\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zUoVVslNghrg"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self,input_size,hidden_dim_1,hidden_dim_2,num_classes,drop_prob=0.5):\n",
        "      super(MLP, self).__init__()\n",
        "      #Put GeneModel architecture here (WITHOUT THE FINAL LAYERS)\n",
        "      self.hidden_dim_1=hidden_dim_1\n",
        "      self.hidden_dim_2=hidden_dim_2\n",
        "      self.num_classes=num_classes\n",
        "      \n",
        "      #self.flantten=torch.flatten()\n",
        "      self.fc_1=nn.Linear(input_size,hidden_dim_1)\n",
        "      self.fc_2=nn.Linear(hidden_dim_1,hidden_dim_2)\n",
        "      self.fc_3=nn.Linear(hidden_dim_2,num_classes)\n",
        "\n",
        "      self.relu = nn.ReLU()\n",
        "      self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "      #Put GeneModel architecture here (WITHOUT THE FINAL LAYERS)\n",
        "      x=x.float()\n",
        "      x=self.fc_1(x)\n",
        "      x=self.dropout(x)\n",
        "      x=self.relu(x)\n",
        "      x=self.fc_2(x)\n",
        "      x=self.dropout(x)\n",
        "      x=self.relu(x)\n",
        "      x=self.fc_3(x)\n",
        "      return x\n",
        "    \n",
        "    def train_model(self, train_loader, optimizer, criterion):\n",
        "      train_loss = 0.0\n",
        "      for X, y in train_loader:\n",
        "        # Setup \n",
        "        X = X.cuda()\n",
        "        y = y.cuda()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Send batch through \n",
        "        pred = mlp(X)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "      return train_loss\n",
        "\n",
        "    def validate_model(self, val_loader, criterion):\n",
        "      val_loss_sum = 0.0\n",
        "      for X, y in val_loader:\n",
        "        X = X.cuda()\n",
        "        y = y.cuda()\n",
        "        \n",
        "        pred = mlp(X)\n",
        "        val_loss = criterion(pred, y)\n",
        "        val_loss_sum += val_loss.item()\n",
        "      \n",
        "      return val_loss_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g5UM0JlKhMz7"
      },
      "outputs": [],
      "source": [
        "# Setup model and hyper parameters\n",
        "mlp = MLP(input_size=9, hidden_dim_1=8, hidden_dim_2=8, num_classes=8, drop_prob=0.0).cuda()\n",
        "lr = 0.001\n",
        "optimizer = optim.Adam(mlp.parameters(), lr=lr)\n",
        "epochs = 1000\n",
        "batch_size = 32\n",
        "class_weights = torch.Tensor([2.4433, 6.319, 8.3295, 7.33, 0.371,0.49, 0.7541, 0.8983]).cuda()\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Setup dataloaders\n",
        "train_csv = \"train_norm.csv\"\n",
        "val_csv = \"val_norm.csv\"\n",
        "train_dataset = CSVDataset(train_csv)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataset = CSVDataset(val_csv)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pprh4SjhqV8B",
        "outputId": "5830fb57-59dc-4b0b-fc6b-38f02a94e2c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 0 / 999\n",
            "Training loss = 2.4338079950083857\n",
            "Validation loss = 2.3543388066084487\n",
            "EPOCH 1 / 999\n",
            "Training loss = 2.4084716102351313\n",
            "Validation loss = 2.336502412091131\n",
            "EPOCH 2 / 999\n",
            "Training loss = 2.3897207832854725\n",
            "Validation loss = 2.320874281551527\n",
            "EPOCH 3 / 999\n",
            "Training loss = 2.3815991969212242\n",
            "Validation loss = 2.314799453901208\n",
            "EPOCH 4 / 999\n",
            "Training loss = 2.377018585153248\n",
            "Validation loss = 2.3138343147609546\n",
            "EPOCH 5 / 999\n",
            "Training loss = 2.3719577944797017\n",
            "Validation loss = 2.3140679546024487\n",
            "EPOCH 6 / 999\n",
            "Training loss = 2.3838942569235098\n",
            "Validation loss = 2.314758026081583\n",
            "EPOCH 7 / 999\n",
            "Training loss = 2.377754322860552\n",
            "Validation loss = 2.31509848781254\n",
            "EPOCH 8 / 999\n",
            "Training loss = 2.3755085001821103\n",
            "Validation loss = 2.315525277801182\n",
            "EPOCH 9 / 999\n",
            "Training loss = 2.3684334210727527\n",
            "Validation loss = 2.316953876744146\n",
            "EPOCH 10 / 999\n",
            "Training loss = 2.369757153417753\n",
            "Validation loss = 2.3155417494151904\n",
            "EPOCH 11 / 999\n",
            "Training loss = 2.371061510365942\n",
            "Validation loss = 2.316223434779955\n",
            "EPOCH 12 / 999\n",
            "Training loss = 2.3709546975467517\n",
            "Validation loss = 2.315987307092418\n",
            "EPOCH 13 / 999\n",
            "Training loss = 2.370759965285011\n",
            "Validation loss = 2.316377473914105\n",
            "EPOCH 14 / 999\n",
            "Training loss = 2.370874718479488\n",
            "Validation loss = 2.3164249295773716\n",
            "EPOCH 15 / 999\n",
            "Training loss = 2.378756028154622\n",
            "Validation loss = 2.317016197287518\n",
            "EPOCH 16 / 999\n",
            "Training loss = 2.370223907024964\n",
            "Validation loss = 2.3170783778895503\n",
            "EPOCH 17 / 999\n",
            "Training loss = 2.3691750142885293\n",
            "Validation loss = 2.3182074401689614\n",
            "EPOCH 18 / 999\n",
            "Training loss = 2.3685316508230954\n",
            "Validation loss = 2.317216966463172\n",
            "EPOCH 19 / 999\n",
            "Training loss = 2.369046501491381\n",
            "Validation loss = 2.3171518159949263\n",
            "EPOCH 20 / 999\n",
            "Training loss = 2.3668381843877877\n",
            "Validation loss = 2.3176615756490957\n",
            "EPOCH 21 / 999\n",
            "Training loss = 2.3670090696086055\n",
            "Validation loss = 2.3178104680517446\n",
            "EPOCH 22 / 999\n",
            "Training loss = 2.36588187450948\n",
            "Validation loss = 2.3173276082329126\n",
            "EPOCH 23 / 999\n",
            "Training loss = 2.366344555564549\n",
            "Validation loss = 2.3187019721321436\n",
            "EPOCH 24 / 999\n",
            "Training loss = 2.366380845722945\n",
            "Validation loss = 2.318691409152487\n",
            "EPOCH 25 / 999\n",
            "Training loss = 2.366162024114443\n",
            "Validation loss = 2.3178064564000005\n",
            "EPOCH 26 / 999\n",
            "Training loss = 2.3626812683499376\n",
            "Validation loss = 2.318824586660966\n",
            "EPOCH 27 / 999\n",
            "Training loss = 2.3664309874824854\n",
            "Validation loss = 2.3199360526126362\n",
            "EPOCH 28 / 999\n",
            "Training loss = 2.361320005810779\n",
            "Validation loss = 2.3198634075081865\n",
            "EPOCH 29 / 999\n",
            "Training loss = 2.362032657084258\n",
            "Validation loss = 2.3202456650526626\n",
            "EPOCH 30 / 999\n",
            "Training loss = 2.3673309942950373\n",
            "Validation loss = 2.3205693545548813\n",
            "EPOCH 31 / 999\n",
            "Training loss = 2.364542174598445\n",
            "Validation loss = 2.321884575097457\n",
            "EPOCH 32 / 999\n",
            "Training loss = 2.3611525452655293\n",
            "Validation loss = 2.320709757182909\n",
            "EPOCH 33 / 999\n",
            "Training loss = 2.359998198954955\n",
            "Validation loss = 2.3203210208726968\n",
            "EPOCH 34 / 999\n",
            "Training loss = 2.3670591349187107\n",
            "Validation loss = 2.321683940680131\n",
            "EPOCH 35 / 999\n",
            "Training loss = 2.3637301040732344\n",
            "Validation loss = 2.3210437297821045\n",
            "EPOCH 36 / 999\n",
            "Training loss = 2.359198631151863\n",
            "Validation loss = 2.3219556601151177\n",
            "EPOCH 37 / 999\n",
            "Training loss = 2.368033175883086\n",
            "Validation loss = 2.322628456613292\n",
            "EPOCH 38 / 999\n",
            "Training loss = 2.3605604210625524\n",
            "Validation loss = 2.3223940237708716\n",
            "EPOCH 39 / 999\n",
            "Training loss = 2.3606496103431867\n",
            "Validation loss = 2.3243483719618423\n",
            "EPOCH 40 / 999\n",
            "Training loss = 2.3618716934452886\n",
            "Validation loss = 2.3233453760976377\n",
            "EPOCH 41 / 999\n",
            "Training loss = 2.364357347073762\n",
            "Validation loss = 2.322007288103518\n",
            "EPOCH 42 / 999\n",
            "Training loss = 2.3591510549835535\n",
            "Validation loss = 2.3249911069869995\n",
            "EPOCH 43 / 999\n",
            "Training loss = 2.3614851158598196\n",
            "Validation loss = 2.325030979902848\n",
            "EPOCH 44 / 999\n",
            "Training loss = 2.3580224824988325\n",
            "Validation loss = 2.324297143065411\n",
            "EPOCH 45 / 999\n",
            "Training loss = 2.3683867350868555\n",
            "Validation loss = 2.327016970385676\n",
            "EPOCH 46 / 999\n",
            "Training loss = 2.3628136904343315\n",
            "Validation loss = 2.3259874530460523\n",
            "EPOCH 47 / 999\n",
            "Training loss = 2.360853437496268\n",
            "Validation loss = 2.3282942979232124\n",
            "EPOCH 48 / 999\n",
            "Training loss = 2.3592601470325305\n",
            "Validation loss = 2.326686470404915\n",
            "EPOCH 49 / 999\n",
            "Training loss = 2.361370411903962\n",
            "Validation loss = 2.324941738792088\n",
            "EPOCH 50 / 999\n",
            "Training loss = 2.358879195607227\n",
            "Validation loss = 2.325427584026171\n",
            "EPOCH 51 / 999\n",
            "Training loss = 2.3571436742077703\n",
            "Validation loss = 2.3282737213632334\n",
            "EPOCH 52 / 999\n",
            "Training loss = 2.3618172744046086\n",
            "Validation loss = 2.3278311335522197\n",
            "EPOCH 53 / 999\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-89266fb66f7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mt_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training loss =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-86b1a2759eaa>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i, epoch in enumerate(range(epochs)):\n",
        "    print(f\"EPOCH {i} / {epochs - 1}\")\n",
        "    \n",
        "    # Set to train() mode and run one epoch\n",
        "    mlp.train()\n",
        "    t_loss = mlp.train_model(train_loader, optimizer, criterion)\n",
        "    print(\"Training loss =\", t_loss / len(train_loader))\n",
        "\n",
        "    # Set to eval() mode and run one epoch\n",
        "    with torch.no_grad():\n",
        "      mlp.eval()\n",
        "      v_loss = mlp.validate_model(val_loader, criterion)\n",
        "    print(\"Validation loss =\", v_loss / len(val_loader))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional save notebook to "
      ],
      "metadata": {
        "id": "yvntxRggcB5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}